{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#processing input training and testing dataset\n",
    "def processInput( Train, Is_Test ):\n",
    "    \n",
    "    Train.fillna(0, inplace = True ) #remove nulls\n",
    "\n",
    "    #Encoding\n",
    "    Train[\"MSSubClass\"] = Train[\"MSSubClass\"].astype(object)\n",
    "    OneHotColumns = list( Train.select_dtypes(include = ['object']).columns )\n",
    "    OneHotDF = Train[OneHotColumns]\n",
    "    OneHotDF = pd.get_dummies(OneHotDF)\n",
    "\n",
    "    Train = Train.drop(OneHotColumns,axis=1)\n",
    "    Train = Train.join(OneHotDF)\n",
    "    \n",
    "    if Is_Test == False :\n",
    "        TrainTarget = Train['SalePrice']\n",
    "        Train = Train.drop('SalePrice',axis=1)\n",
    "        Train.drop(\"Id\", axis=1)\n",
    "        return Train, TrainTarget\n",
    "    else :\n",
    "        Id = Train['Id']\n",
    "        Train.drop(\"Id\", axis=1)\n",
    "        return Train, Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove descripancies in processed test and train dataset\n",
    "def add_missing_dummy_columns( d, columns ):\n",
    "    missing_cols = set( columns ) - set( d.columns )\n",
    "    for c in missing_cols:\n",
    "        d[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
      "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "\n",
      "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0      2   2008        WD         Normal     208500  \n",
      "1      5   2007        WD         Normal     181500  \n",
      "2      9   2008        WD         Normal     223500  \n",
      "3      2   2006        WD        Abnorml     140000  \n",
      "4     12   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "Train = pd.read_csv( \"train.csv\" )\n",
    "print Train.head()\n",
    "Train, TrainTarget = processInput( Train, False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(Train, TrainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933629916316\n"
     ]
    }
   ],
   "source": [
    "print reg.score(Train,TrainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Test = pd.read_csv( \"test.csv\" )\n",
    "Test, Id = processInput( Test, True );\n",
    "\n",
    "add_missing_dummy_columns(Train, Test.columns)\n",
    "add_missing_dummy_columns(Test, Train.columns)\n",
    "\n",
    "Test = Test[Train.columns]\n",
    "# TrainColumns = Train.columns\n",
    "# TestColumns = Test.columns\n",
    "\n",
    "# DiffAB = set(TrainColumns) - set(TestColumns)\n",
    "# DiffAB = list(DiffAB)\n",
    "# print DiffAB\n",
    "\n",
    "# DiffBA = set(TestColumns) - set(TrainColumns)\n",
    "# DiffBA = list(DiffBA)\n",
    "# print DiffBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_values = reg.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id      SalePrice\n",
      "0  1461  112045.500351\n",
      "1  1462  163025.284224\n",
      "2  1463  188485.539722\n",
      "3  1464  197947.787132\n",
      "4  1465  207377.235589\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "df_final['Id'] = Id\n",
    "df_final['SalePrice'] = predicted_values\n",
    "print df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
